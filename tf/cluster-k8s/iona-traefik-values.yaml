# the ordering in this file should match the upstream values.yaml last updated
# from
# https://raw.githubusercontent.com/traefik/traefik-helm-chart/78dc3f2b6cd5af5e32b68f3feb0677bfdab3fa89/traefik/values.yaml
deployment:
  labels:
    "app.kubernetes.io/name": "traefik"
    "app.kubernetes.io/part-of": "traefik"
  # TODO: strategy: type = "Recreate" so it can run as host network single
  # instance in ingress-pool
  initContainers:
    - name: data-volume-permissions
      image: "busybox:1.31.1"
      command: ["sh", "-c", "mkdir -p /data/letsencrypt && touch /data/letsencrypt/acme-staged.json && chmod -Rv 600 /data/letsencrypt/*"]
      volumeMounts:
        - name: data
          mountPath: /data

providers:
  redis:
    endpoints:

  kubernetesCRD:
    # routes can only reference services in their own namespace
    # allowCrossNamespace: false

    # XXX: TODO: I think this is necessary to proxy to github pages for static
    # content
    allowExternalNameServices: true
  kubernetesingress:
    enabled: false

volumes:
  - name: traefik-default-routes
    type: configMap
    mountPath: "/etc/traefik/dynamic/default-routes"
# additionalVolumeMounts

logs:
  general:
    level: DEBUG
  access:
    enabled: true
    fields:
      headers:
        defaultmode: keep

# metrics:
# globalArguments:
# All available options available on https://docs.traefik.io/reference/static-configuration/cli/
## Use curly braces to pass values: `helm install --set="additionalArguments={--providers.kubernetesingress.ingressclass=traefik-internal,--log.level=DEBUG}"`
additionalArguments:
  - --api.insecure=true
  #- --entrypoints.web.address=:80
  #- --entrypoints.websecure.address=:443
  #- --entrypoints.ping.address=:10254
  # - --ping.entrypoint=ping
  - --providers.file.directory=/etc/traefik/dynamic/default-routes
  - --providers.redis=true
  - --providers.redis.entrypoints=${REDIS_ENDPOINT}
  # - --providers.redis.tls.ca=${REDIS_SERVER_CA}
  # - --providers.redis.tls.key=${REDIS_CLIENT_KEY}
  # - --providers.redis.tls.cert=${REDIS_CLIENT_CERT}
  - --certificatesresolvers.letsencrypt.acme.dnschallenge=true
  - --certificatesresolvers.letsencrypt.acme.dnschallenge.provider=gcloud
  - --certificatesresolvers.letsencrypt.acme.caserver=https://acme-staging-v02.api.letsencrypt.org/directory
  - --certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL}
  - --certificatesresolvers.letsencrypt.acme.storage=/data/letsencrypt/acme-staging.json
#  - "--providers.kubernetesingress.ingressclass=traefik-internal"
#  - "--log.level=DEBUG"

envFrom:
  - configMapRef:
      name: traefik-env

ports:
  websecure:
    tls:
      enabled: true
      certResolver: letsencrypt
      domains:
        - main: "thaumagen.io"
          sans: "*.thaumagen.io"

service:
  type: ClusterIP
  # type: LoadBalancer - this picks up the kubeip static ip for the ingress
  # node and GCP creates a target-pool + forwarding rule. If we go this road,
  # provided we sort out KV store for letsencrypt certs, we can drop the
  # envoy-lb service all together. We would need to do this bit in HCL to
  # cleanly inject the static ip address
  # see https://cloud.google.com/load-balancing/docs/target-pools

persistence:
  # using letsencrypt with persistence assumes we only use a single traefik
  # replica. if load gets to high for that to be tenable the answer is:
  # certmanager https://cert-manager.io/docs/installation/helm/
  # OR KV store backed by memorstore (redis)
  # Adding memorstore is likely more bangfor buck and its free
  enabled: true

rbac:
  # created independenty in tf
  enabled: false

serviceAccount:
  name: "dns01solver-sa"

# Additional serviceAccount annotations (e.g. for oidc authentication)
serviceAccountAnnotations: {}
resources:
  requests:
    cpu: "100m"
    memory: "50Mi"
  limits:
    cpu: "300m"
    memory: "150Mi"

# need to set strategy=Replace for this to work reliably
#nodeSelector:
#  "cloud.google.com/gke-nodepool": "ingress-pool"

# tolerations:
#   - key: "ingress-pool"
#     operator: "Equal"
#     value: "true"
